{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner products and Norms.\n",
    "\n",
    "The geometry of the Euclidean space is founded on the familiar properties of length and angle. The abstract concept of a norm on a vector space formalizes the geometrical notion of the length of a vector. In Euclidean geometry, the angle between two vectors is specified by their dot product, which is itself formalized by the abstract conept of an inner-product. Inner products and norms lie at the heart of linear(and non-linear) analysis, in both finite-dimensional and infinite dimensional vector-spaces. A vector space equipped with an inner product and its associated norm is known as an inner product space. It is impossible to overemphasize their importance for theoretical developments, practical applications and the design of numerical solution algorithms.\n",
    "\n",
    "Mathematical analysis relies on the exploitation of inequalities. The most fundamental is the Cauchy-Schwarz inequality, which is valid in every inner-product space. The more familiar triangle inequality for the associated norm is then derived as a simple consequence. Not every norm comes from an inner product, and in, such cases, the triangle inequality becomes part of the general definition. Both inequalities retain their validity in both finite dimensional and infinite dimensional vector spaces. Indeed, their abstract formulation exposes the key ideas behind the proof, avoiding all distracting particularities appearing in the explicit formulas.\n",
    "\n",
    "The characterization of general inner products on Euclidean space will lead to the noteworthy class of positive definite matrices. Positive definite matrices appear in a wide variety of applications, including minimization, least squares, data analysis and statistics, as well as, for example, mechanical systems, electrical circuits, and the differential equations describing both static and dynamical processes. The test for positive definiteness relies on Gaussian elimination, and we can reinterprete the resulting matrix factorization as the algebraic process of completing the square for the associated quadratic form. In applications, positive definite matrices most often arise as Gram matrices, whose entries are formed by taking inner products between selected elements of an inner product space. \n",
    "\n",
    "## Inner products.\n",
    "\n",
    "The most basic example of an inner product is the familiar dot product\n",
    "\n",
    "$\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}$\n",
    "$\\newcommand{\\inner}[2]{\\left\\langle #1, #2 \\right\\rangle}$\n",
    "\n",
    "$\\begin{align*}\n",
    "\\mathbf{v}\\cdot \\mathbf{w} = v_1 w_1 + v_2 w_2 + \\ldots + v_n w_n = \\sum_{i=1}^{n}v_i w_i\n",
    "\\end{align*}$\n",
    "\n",
    "between column vectors $\\mathbf{v} = (v_1,v_2,\\ldots,v_n)^T$,  $\\mathbf{w} = (w_1,w_2,\\ldots,w_n)^T$, both lying in the Euclidean space $\\mathbb{R}^n$. A key observation is that, the dot product is equal to the matrix product\n",
    "\n",
    "$\\begin{align*}\n",
    "\\mathbf{v}\\cdot \\mathbf{w} = \\mathbf{v}^T \\cdot \\mathbf{w} = \n",
    "\\begin{bmatrix} v_1 & v_2 & \\ldots & v_n \\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots\\\\\n",
    "w_n\n",
    "\\end{bmatrix}\n",
    "\\end{align*}$\n",
    "\n",
    "The dot product is the cornerstone of Euclidean geometry. The key fact is that the dot product of a vector with itself,\n",
    "\n",
    "$\\begin{align*}\n",
    "\\mathbf{v}\\cdot \\mathbf{v} = v_1^2 + v_2^2 + \\ldots + v_n^2 = \\sum_{i=1}^{n}v_i^2\n",
    "\\end{align*}$\n",
    "\n",
    "is the sum of the squares of its entries, and hence, by the classsical Pythagorean Theorem, equals the square of its length. Consequently, the Euclidean norm or length of a vector is found by taking the square root:\n",
    "\n",
    "$\\begin{align*}\n",
    "\\lvert \\lvert \\mathbf{v}\\rvert\\rvert = \\sqrt{\\mathbf{v} \\cdot \\mathbf{v}} = \\sqrt{v_1^2 + v_2^2 + \\ldots + v_n^2}\n",
    "\\end{align*}$\n",
    "\n",
    "Note that, every non-zero vector, $\\mathbf{v} \\ne \\mathbf{0}$, has a positive Euclidean norm, $\\norm{\\mathbf{v}} > 0$, while only the zero vector has the zero norm: $\\norm{\\mathbf{v}}=0$ if and only $\\mathbf{v} = \\mathbf{0}$. The elementary properties of dot product and Euclidean norm serve to inspire the abstract definition of more general inner products.\n",
    "\n",
    "**Definition**. An *inner product* on the real vector space $V$ is a pairing that takes two vectors $\\mathbf{v},\\mathbf{w} \\in V$ and produces a real number $\\inner{v,w} \\in \\mathbb{R}$. The inner product is required to satisfy the following three axioms for all $\\mathbf{u},\\mathbf{v},\\mathbf{w} \\in V$ and scalars $c,d\\in\\mathbb{R}$.\n",
    "\n",
    "(i) *Bilinearity*. \n",
    "\n",
    "$\\inner{c\\mathbf{u}+d\\mathbf{v}}{\\mathbf{w}} = c\\inner{\\mathbf{u}}{\\mathbf{v}} + d\\inner{\\mathbf{v}}{\\mathbf{w}}$\n",
    "\n",
    "$\\inner{\\mathbf{u}}{c\\mathbf{v}+d\\mathbf{w}} = c\\inner{\\mathbf{u}}{\\mathbf{v}} + d\\inner{\\mathbf{v}}{\\mathbf{w}}$\n",
    "\n",
    "(ii) *Symmetry*.\n",
    "\n",
    "$\\inner{\\mathbf{v}}{\\mathbf{w}} = \\inner{\\mathbf{w}}{\\mathbf{v}}$\n",
    "\n",
    "(iii) *Positivity*.\n",
    "\n",
    "$\\inner{\\mathbf{v}}{\\mathbf{v}} \\ge 0$ \n",
    "\n",
    "$\\inner{\\mathbf{v}}{\\mathbf{v}} = 0$ if and only if $\\mathbf{v} = \\mathbf{0}$\n",
    "\n",
    "A vector space equipped with an inner product is called an *inner product space*. As we shall see, a vector space can admit many different inner products. Verification of the inner product axioms for the Euclidean dot product is straight-forward.\n",
    "\n",
    "Verification.\n",
    "\n",
    "Let $\\mathbf{u} = (u_1,u_2), \\mathbf{v} = (v_1,v_2), \\mathbf{w} = (w_1,w_2)$\n",
    "\n",
    "(i) Bilinearity.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\langle c\\mathbf{u} + d\\mathbf{v},\\mathbf{w} \\rangle &= \\langle (cu_1+dv_1,cu_2+dv_2),(w_1,w_2)\\rangle\\\\\n",
    "&=cu_1 w_1 + dv_1 w_1 + cu_2 w_2 + dv_2 w_2 = c(u_1 w_1 + u_2 w_2) + d(v_1 w_1 + v_2 w_2)\\\\\n",
    "&= c \\langle \\mathbf{u},\\mathbf{w} \\rangle + d \\langle \\mathbf{v},\\mathbf{w} \\rangle\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "(ii) Symmetry.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\langle \\mathbf{v},\\mathbf{w} \\rangle &= v_1 w_1 + v_2 w_2\\\\\n",
    "&=w_1 v_1 + w_2 v_2\\\\\n",
    "&=  \\langle\\mathbf{w},\\mathbf{v} \\rangle \n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "(iii) Semi-positive definiteness\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\langle \\mathbf{v},\\mathbf{v} \\rangle &= v_1^2 + v_2^2 \\ge 0\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Because, $v_1^2 + v_2^2 = 0 \\iff v_1 = v_2 = 0$, we have $||\\mathbf{v}|| = 0 \\iff \\mathbf{v} = \\mathbf{0}$.\n",
    "\n",
    "Example. Let $c_1,c_2,\\ldots,c_n > 0$ be a set of positive numbers. The corresponding *weighted inner product* and *weighted norm* on $\\mathbb{R}^n$ are defined by,\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\langle \\mathbf{v},\\mathbf{w} \\rangle &= \\sum_{i=1}^{n}c_i v_i w_i\\\\\n",
    "||v|| &= \\sqrt{\\langle \\mathbf{v},\\mathbf{v}\\rangle}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "The numbers $c_i$ are called *weights*. Observe that the larger the weight $c_i$, the more the $i$th coordinate of $\\mathbf{v}$ contributes to the norm. Weighted norms are particularly relevant in statistics and data-fitting, when one wants to emphasize the importance of certain measurements and de-emphasize others; this is done by assigning appropriate weights to the components of the data vector $\\mathbf{v}$.\n",
    "\n",
    "*Problem*. Prove that the norm on an inner product space satisfies $||c\\mathbf{v}|| = |c| \\space ||\\mathbf{v}||$ for every scalar $c$ and vector $\\mathbf{v}$.\n",
    "\n",
    "*Proof*.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "||c\\mathbf{v}|| &= ||(cv_1,cv_2)||\\\\\n",
    "&= \\sqrt{c^2 v_1^2 + c^2 v_2^2}\\\\\n",
    "&= |c|\\sqrt{v_1^2 + v_2^2}\\\\\n",
    "&= |c| \\space ||\\mathbf{v}||\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Problem. Prove that $\\langle a\\mathbf{v} +v \\mathbf{w},c\\mathbf{v}+d\\mathbf{w} \\rangle = ac ||\\mathbf{v}||^2 + (ad + bc) \\langle v,w \\rangle + bd ||\\mathbf{w}||^2$.\n",
    "\n",
    "Proof. \n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\langle a\\mathbf{v} +v \\mathbf{w},c\\mathbf{v}+d\\mathbf{w} \\rangle &= a \\langle \\mathbf{v},c\\mathbf{v} + d\\mathbf{w}\\rangle + b \\langle \\mathbf{w},c\\mathbf{v} + d \\mathbf{w} \\rangle\\\\\n",
    "&= ac \\langle \\mathbf{v},\\mathbf{v} \\rangle + ad \\langle \\mathbf{v},\\mathbf{w} \\rangle + bc \\langle \\mathbf{w},\\mathbf{v} \\rangle + bd \\langle \\mathbf{w},\\mathbf{w} \\rangle \\\\\n",
    "&= ac ||\\mathbf{v}||^2 + (ad+bc) \\langle \\mathbf{v},\\mathbf{w}\\rangle + bd ||w||^2\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "*Problem*. Prove that $\\mathbf{x}\\in \\mathbb{R}^n$ solves the linear system $A\\mathbf{x} = \\mathbf{b}$ if and only if\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\mathbf{x}^T A^T \\mathbf{v} = \\mathbf{b}^T \\mathbf{v} \n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "for all $\\mathbf{v} \\in \\mathbb{R}^m$.\n",
    "\n",
    "The latter is known as the *weak formulation* of the linear system and its generalizations are of great importance in the study of differential equations and numerical analysis.\n",
    "\n",
    "*Proof*.\n",
    "\n",
    "If $\\mathbf{x}$ is the solution of the LSE $A\\mathbf{x} = \\mathbf{b}$, then for any vector $\\mathbf{v}$, we must have:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\langle A\\mathbf{x},\\mathbf{v}\\rangle &= \\langle \\mathbf{b},\\mathbf{v} \\rangle\\\\\n",
    "\\mathbf{x}^T A^T \\mathbf{v} &= \\mathbf{b}^T \\mathbf{v}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "## Inner products on Function Spaces.\n",
    "\n",
    "Inner products and norms on function spaces lie at the foundation of modern analysis and its applications, particularly Fourier Analysis, boundary value problems, ordinary and partial differential equations, and numerical analysis. Let us introduce the most important examples. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
