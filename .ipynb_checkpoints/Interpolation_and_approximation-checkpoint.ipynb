{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation and Approximation.\n",
    "\n",
    "## The Interpolation Problem.\n",
    "\n",
    "Polynomials are used as the basic means of approximation by nearly all areas of numerical analysis. In the following sections, we shall go deeper into the non-equidistant interpolation problem:\n",
    "\n",
    "Let $a = x_1 < x_2 < \\ldots < x_n = b$ be a grid of distinct points $x_i$. Let $\\mathcal{P}_n$ be the vector space of all polynomials in one variable of degree less than $n$. The interpolation problem to find a polynomial $p \\in \\mathcal{P}_n$, such that \n",
    "\n",
    "$$\n",
    "p(x_i) = f(x_i)\n",
    "$$\n",
    "\n",
    "for $i=1:n$.\n",
    "\n",
    "**Theorem**. *Weierstrass Approximation Theorem*. \n",
    "\n",
    "If $f(x)$ is a continuous function on the interval $[a,b]$, then we can construct a sequence of polynomials $(P_n)$ that approximates $f$ in the following way:\n",
    "Given any $\\epsilon > 0$, there exists an $N \\in \\mathbf{N}$, such that for all $x \\in [a,b]$, we have\n",
    "\n",
    "$$\\lvert P_n(x) - f(x) \\vert < \\epsilon$$\n",
    "\n",
    "for all $n \\ge N$.\n",
    "\n",
    "*Proof.*\n",
    "\n",
    "Let $f\\in C[a,b]$. Assume $0 < a < b < 1$. We extend out the domain of $f(x)$ to the whole real line by defining\n",
    "\n",
    "$$\n",
    "f(x) := \n",
    "\\begin{cases}\n",
    "0, & x \\le 0\\\\\n",
    "\\frac{x}{a}f(a), & 0 < x < a\\\\\n",
    "f(x), & a \\le x \\le b\\\\\n",
    "\\frac{1 - x}{1 - b}f(b), & b < x < 1\\\\\n",
    "0, & x \\ge 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We see that $f$ is continuous on the whole real line. \n",
    "\n",
    "Consider the sequence of positive constants $J_n$ with\n",
    "\n",
    "$$\n",
    "J_n := \\int_{-1}^{1} (1 - u^2)^n du\n",
    "$$\n",
    "\n",
    "and we define our sequence of polynomials by,\n",
    "\n",
    "$$\n",
    "P_n(x) := \\frac{1}{J_n} \\int_{0}^{1} f(t) [1 - (t - x)^2]^n dt\n",
    "$$\n",
    "\n",
    "It is easy to see that $P_n$ is a polynomial of degree (at most) $2n$ in $x$ with constant coefficients. \n",
    "\n",
    "Now as our function $f$ vanishes outside the interval $[0,1]$ we have for all $x \\in [0,1]$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P_n(x) &= \\frac{1}{J_n} \\int_{0}^{1} f(t) [1 - (t - x)^2]^n dt \\\\\n",
    "&=\\frac{1}{J_n} \\int_{-1+x}^{0} f(t) [1 - (t - x)^2]^n dt + \\frac{1}{J_n} \\int_{0}^{1} f(t) [1 - (t - x)^2]^n dt + \\frac{1}{J_n} \\int_{1}^{1+x} f(t) [1 - (t - x)^2]^n dt  \\\\\n",
    "&= \\frac{1}{J_n} \\int_{-1+x}^{1+x} f(t) [1 - (t - x)^2]^n dt \\\\\n",
    "&= \\frac{1}{J_n} \\int_{-1}^{1} f(x+u) [1 - (u)^2]^n du \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where we have used the substitution $u = t - x$ in the last step. When $t = -1 + x$, $u = -1$ and when $t = 1 + x$, $u = 1$.\n",
    "\n",
    "We consider,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P_n(x) - f(x) &= \\frac{1}{J_n} \\int_{-1}^{1} f(x+u) [1 - (u)^2]^n du - f(x)\\\\\n",
    "&= \\frac{1}{J_n} \\int_{-1}^{1} f(x+u) [1 - (u)^2]^n du - \\frac{1}{J_n}\\cdot J_n f(x)\\\\\n",
    "&= \\frac{1}{J_n} \\int_{-1}^{1} f(x+u) [1 - (u)^2]^n du - \\frac{1}{J_n}\\int_{-1}^{1}f(x)[1 - (u)^2]^n du\\\\\n",
    "&= \\frac{1}{J_n} \\int_{-1}^{1} (f(x+u) - f(x)) [1 - (u)^2]^n du\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Let $\\epsilon > 0$. Since the function $f$ is uniformly continuous, for every $\\epsilon > 0$, there exists a $\\delta > 0$, such that whenever $\\lvert u \\rvert < \\delta$, we have:\n",
    "\n",
    "$$\n",
    "\\lvert f(x + u) - f(x) \\rvert < \\frac{\\epsilon}{2}\n",
    "$$\n",
    "\n",
    "Since $f$ is continuous over the entire real line, if $M > 0$ is the maximum value of the function $f$, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lvert f(x + u) - f(x) \\rvert &\\le \\lvert f(x + u) \\rvert + \\lvert f(x) \\rvert\\\\\n",
    "&\\le M + M = 2M\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "for all $u$.\n",
    "\n",
    "For $\\lvert u \\rvert > \\delta$, we have:\n",
    "\n",
    "$$\n",
    "1 \\le \\frac{u^2}{\\delta^2}\n",
    "$$\n",
    "\n",
    "and so from the above inequalities, we have,\n",
    "$$\n",
    "\\lvert f(x + u) - f(x) \\rvert \\le \\frac{\\epsilon}{2} + \\frac{2M u^2}{\\delta^2}\n",
    "$$\n",
    "\n",
    "So, the distance between $P_n(x)$ and $f(x)$ can be bound by,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lvert P_n(x) - f(x) \\rvert &= \\frac{1}{J_n} \\int_{-1}^{1} \\lvert f(x+u) - f(x) \\rvert [1 - (u)^2]^n du \\\\\n",
    "&\\le \\frac{1}{J_n} \\int_{-1}^{1} \\frac{\\epsilon}{2} \\cdot  [1 - (u)^2]^n du + \\frac{1}{J_n} \\int_{-1}^{1} \\frac{2M u^2}{\\delta^2}  [1 - (u)^2]^n du\\\\\n",
    "&= \\frac{\\epsilon}{2} + \\frac{1}{J_n}\\frac{2M}{\\delta^2}I_n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $(I_n)$ is the sequence of integrals $\\int_{-1}^{1}u^2[1-u^2]^n du$. What we are going to do is, we shall show that the limit $I_n/J_n$ approaches $0$ as $n \\to \\infty$.\n",
    "\n",
    "Using integration by parts, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "I_n &= \\int_{-1}^{1}u \\cdot u[1-u^2]^n du\\\\\n",
    "&= \\int_{-1}^{1} \\frac{[1-u^2]^{n+1}}{2(n+1)}\\\\\n",
    "&= \\frac{J_{n+1}}{2(n+1)}\\\\\n",
    "&< \\frac{J_n}{2n}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "since it can be shown that $J_{n+1} \\le J_n$. Consequently, $\\lvert I_n/J_n \\rvert < \\frac{1}{2n}$, so by the comparison test, $I_n/J_n$ is convergent and approaches zero. Given any $\\epsilon > 0$, we can make the distance $\\lvert I_n/J_n \\rvert < \\frac{\\delta^2}{M}\\epsilon $.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lvert P_n(x) - f(x) \\rvert \n",
    "&\\le \\frac{\\epsilon}{2} + \\frac{1}{J_n}\\frac{2M}{\\delta^2}I_n \\\\\n",
    "&< \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Bases for Polynomial Interpolation.\n",
    "\n",
    "A set of polynomials $\\mathbf{p} = \\{p_1(x),p_2(x),\\ldots,p_n(x)\\}$, such that any polynomial $p \\in \\mathcal{P}_n$ can be expressed as a linear combination \n",
    "\n",
    "$$\n",
    "p(x) = \\sum_{j=1}^{n} c_j p_j(x)\n",
    "$$\n",
    "\n",
    "is called a basis of $\\mathcal{P}_n$. The column vector $c=(c_1,c_2,c_3,\\ldots,c_n)^T$ can be viewed as the coordinates of the polynomial $p$ in the vector space $\\mathcal{P}_n$, with respect to this basis. Thus, the interpolation problem leads to a system of linear equations:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "c_1p_1(x_1) + c_2p_2(x_1) + \\ldots + c_mp_m(x_1) &= f(x_1)\\\\\n",
    "c_1p_1(x_2) + c_2p_2(x_2) + \\ldots + c_mp_m(x_2) &= f(x_2)\\\\\n",
    "\\vdots\\\\\n",
    "c_1p_1(x_n) + c_2p_2(x_n) + \\ldots + c_mp_m(x_n) &= f(x_n)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In matrix notation,\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "p_1(x_1) & p_2(x_1) & \\ldots & p_m(x_1)\\\\\n",
    "p_1(x_2) & p_2(x_2) & \\ldots & p_m(x_2)\\\\\n",
    "\\vdots   & \\vdots   &        & \\vdots \\\\\n",
    "p_1(x_n) & p_2(x_n) & \\ldots & p_m(x_n)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "c_1\\\\\n",
    "c_2\\\\\n",
    "\\vdots\\\\\n",
    "c_m\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "f(x_1)\\\\\n",
    "f(x_2)\\\\\n",
    "\\vdots\\\\\n",
    "f(x_n)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "M_n(\\mathbf{p})c = f\n",
    "$$\n",
    "\n",
    "Since, the interpolation polynomial for any function $f$ is unique, mathematically the choice of basis (for a finite-dimensional space) makes no difference. Computationally, working with *rounded values of the coefficients*, the choice of basis can make a great difference.\n",
    "\n",
    "For the power basis, $p_j(x) = x^{j-1}$, the coefficients of the interpolation polynomial is given by the solution of the linear system $V_n^T c = f$, where $V_n$ is the Vandermonde Matrix.\n",
    "\n",
    "$$\n",
    "V_n = \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & \\ldots & 1\\\\\n",
    "x_1 & x_2 & x_3 & \\ldots & x_n\\\\\n",
    "x_1^2 & x_2^2 & x_3^2 & \\ldots & x_n^2\\\\\n",
    "x_1^3 & x_2^3 & x_3^3 & \\ldots & x_n^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1^{n-1} & x_2^{n-1} & x_3^{n-1} & \\ldots & x_n^{n-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix is non-singular since the Vandermonde determinant can be simplified as,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\det{V_n} &=  \n",
    "\\begin{array}{|ccccc|}\n",
    "1 & 1 & 1 & \\ldots & 1\\\\\n",
    "x_1 & x_2 & x_3 & \\ldots & x_n\\\\\n",
    "x_1^2 & x_2^2 & x_3^2 & \\ldots & x_n^2\\\\\n",
    "x_1^3 & x_2^3 & x_3^3 & \\ldots & x_n^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1^{n-1} & x_2^{n-1} & x_3^{n-1} & \\ldots & x_n^{n-1}\\\\\n",
    "\\end{array}\\\\\n",
    "&= \n",
    "\\begin{array}{|ccccc|}\n",
    "1 & 0 & 0 & \\ldots & 0\\\\\n",
    "x_1 & x_2 - x_1 & x_3 - x_1 & \\ldots & x_n - x_1\\\\\n",
    "x_1^2 & x_2^2 - x_1^2 & x_3^2 - x_1^2 & \\ldots & x_n^2 - x_1^2\\\\\n",
    "x_1^3 & x_2^3 - x_1^3 & x_3^3 - x_1^2& \\ldots & x_n^3 - x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1^{n-1} & x_2^{n-1} -x_1^{n-1}   & x_3^{n-1}-x_1^{n-1}  & \\ldots & x_n^{n-1} -x_1^{n-1} \n",
    "\\end{array}\\\\\n",
    "&=\\begin{array}{|cccc|}\n",
    "x_2 - x_1 & x_3 - x_1 & \\ldots & x_n - x_1\\\\\n",
    "x_2^2 - x_1^2 & x_3^2 - x_1^2 & \\ldots & x_n^2 - x_1^2\\\\\n",
    "x_2^3 - x_1^3 & x_3^3 - x_1^2& \\ldots & x_n^3 - x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_2^{n-1} -x_1^{n-1}   & x_3^{n-1}-x_1^{n-1}  & \\ldots & x_n^{n-1} -x_1^{n-1} \n",
    "\\end{array}\\\\\n",
    "&= (x_2 - x_1)(x_3 - x_1)\\ldots(x_n-x_1)\\begin{array}{|cccc|}\n",
    "1 & 1 & \\ldots & 1\\\\\n",
    "x_2 + x_1 & x_3 + x_1 & \\ldots & x_n + x_1\\\\\n",
    "x_2^2 + x_2x_1 + x_1^2 & x_3^2 + x_3x_1 + x_1^2& \\ldots & x_n^2 +x_nx_1 + x_1^2\\\\\n",
    "\\vdots\n",
    "\\end{array}\\\\\n",
    "&= (x_2 - x_1)(x_3 - x_1)\\ldots(x_n-x_1)\\begin{array}{|cccc|}\n",
    "1 & 0 & \\ldots & 0\\\\\n",
    "x_2 + x_1 & x_3 - x_2 & \\ldots & x_n - x_2\\\\\n",
    "x_2^2 + x_2x_1 + x_1^2 & x_3^2 - x_2^2 + x_1(x_3 - x_2) & \\ldots & x_n^2 - x_2^2 + x_1(x_n - x_2)\\\\\n",
    "\\vdots\n",
    "\\end{array}\\\\\n",
    "&= (x_2 - x_1)\\ldots(x_n-x_1)(x_3-x_2)\\ldots(x_n-x_2)\\begin{array}{|ccc|}\n",
    "1 & \\ldots & 1\\\\\n",
    "x_3 + x_2 + x_1 & \\ldots & x_n+x_2+x_1\\\\\n",
    "\\vdots\n",
    "\\end{array}\\\\\n",
    "&= \\prod_{1\\le i < j \\le n}(x_j - x_i)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This determininant will be identically equal to zero (for all $x$), if and only if $x_i = x_j$. So, the columns of the Vandermonde matrix are linearly independent. \n",
    "\n",
    "Let $\\mathbf{p} = \\{p_1(x),p_2(x),\\ldots,p_n(x)\\}$ and $\\mathbf{q} = \\{q_1(x),q_2(x),\\ldots,q_n(x)\\}$ be two bases for $\\mathcal{P}_n$. Then, the $q_j$ must be some linear combinatios of the $p_k$, $k=1:n$. This can be expressed as a matrix-vector product.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{q}^T = \\mathbf{p}^T S\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $S$ is a constant matrix. $S$ must be non-singular(invertible), for, if $S$ were singular, then the homogenous system of equations $S\\mathbf{v}=\\mathbf{0}$ would have a non-trivial solution vector $\\mathbf{v}$ and hence, \n",
    "\n",
    "$$\n",
    " \\mathbf{q}^T \\mathbf{v}= \\mathbf{p}^T S \\mathbf{v} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "But, that would imply $v_1q_1(x) + \\ldots + v_nq_n(x) = \\mathbf{0}$, where not all of $v_1,v_2,\\ldots,v_n$ are equal to zero. So, $(q_1(x),q_2(x),\\ldots,q_n(x))^T$ is not a basis for $\\mathcal{P}_n$.\n",
    "\n",
    "Let $T$ be the linear transformation that maps the column vector of $c=(c_1,c_2,\\ldots,c_n)^T$ (the coefficients of the interpolation polynomial $p$) to the functional values $f(x_i)$. Let $\\mathbf{p}$ and $\\mathbf{q}$ be two basis of $\\mathcal{P}_n$. Let $M_n(\\mathbf{p})$ and $M_n(\\mathbf{q})$ be the matrix of the linear transformation $T$, with respect to the basis $\\mathbf{p}$ and $\\mathbf{q}$.\n",
    "\n",
    "By putting $x = x_i$, $i=1:m$ in the equation $\\mathbf{q}^T = \\mathbf{p}^T S$, we have from basic linear algebra,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum e_i (q_1(x_i),\\ldots,q_n(x_i)) &= \\sum e_i (p_1(x_i),\\ldots,p_n(x_i)) \\cdot S\\\\\n",
    "M_n(\\mathbf{q}) &= M_n(\\mathbf{p})S\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If we set $p(x) = \\sum d_j q_j(x)$, the linear algebraic system discussed earlier becomes, $M_n(\\mathbf{q})d = f$ and then,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "M_n(\\mathbf{p})c &= f = M_n(\\mathbf{q})d\\\\\n",
    "&= M_n(\\mathbf{p})Sd\\\\\n",
    "c &= Sd = M_n^{-1}(\\mathbf{p})f\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The (change-of-basis) matrix $S$ for the transformation between representations is thus like coordinate transformation in Geometry. \n",
    "\n",
    "The power basis has a bad reputation which is related to the ill-conditioning of the corresponding Vandermonde matrix. There are other basis in $\\mathcal{P}_n$ which are often more advantageous to use. By a *triangle family* of polynomials, we mean a sequence of polynomials \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "q_1(x)&= s_{11}\\\\\n",
    "q_2(x)&= s_{12} + s_{22}x\\\\\n",
    "q_3(x)&= s_{13} + s_{23}x + s_{33}x^2\\\\\n",
    "\\vdots\\\\\n",
    "q_n(x)&= s_{1n} + s_{2n}x + s_{3n}x^2 + \\ldots + s_{nn}x^{n-1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $s_{jj}\\ne 0$ for all $j$. Note that the coefficients form a lower triangular matrix $S$. \n",
    "\n",
    "Conversely, for any $j$, $p_j(x) = x^{j-1}$ can be expressed recursively and uniquely as linear combinations of $q_1(x),q_2(x),\\ldots,q_j(x)$. We obtain a triangle scheme also for the inverse transformation, since we can easily perform forward-substitution and solve for the values of $1,x,x^2,\\ldots,x^n$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "1 &= \\frac{q_1(x)}{s_{11}}\\\\\n",
    "x &= \\frac{q_2(x) - s_{12}(1)}{s_{22}} = \\frac{q_2(x) - s_{12}\\cdot\\frac{q_1(x)}{s_{11}}}{s_{22}} = \\frac{s_{11}q_2 - s_{12}q_1}{s_{11}s_{22}}\\\\\n",
    "x^2 &= \\frac{q_3(x) - s_{13} - s_{23}x}{s_{33}} = \\ldots\\\\\n",
    "\\vdots\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The coefficients form a lower triangular matrix $T = S^{-1}$. Since every triangle family is invertible, it's columns are linearly independent. So, *every triangle family* is a basis for $\\mathcal{P}_m$.\n",
    "\n",
    "Among interesting triangle families are the shifted power basis $(x-c)^j$, the Chebyshev polynomials $T_j(x)$, and many other families of orthogonal polynomials.\n",
    "\n",
    "A triangle family which is often very convenient for solving the interpolation problem is the family of **Newton polynomials**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p_1(x) &= 1\\\\\n",
    "p_2(x) &= (x - x_1)\\\\\n",
    "p_3(x) &= (x - x_1)(x - x_2)\\\\\n",
    "\\vdots\\\\\n",
    "p_j(x) &= (x - x_1)(x - x_2)\\cdots(x - x_{j-1})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "which has unit leading coefficients. Since $p_j(x_k) = 0$, if $k < j$, we obtain using the representation \n",
    "\n",
    "$$\n",
    "p(x) = c_1 p_1(x) + c_2 p_2(x) + c_3 p_3(x)+ \\ldots + c_n p_n(x)\n",
    "$$\n",
    "\n",
    "the lower triangular system $Lc = f$ for the coefficients, where \n",
    "\n",
    "$$\n",
    "\\begin{array}{lllll}\n",
    "p_1(x_1) = 1, & p_2(x_1) = 0, & p_3(x_1) = 0, & \\ldots, & p_n(x_1) = 0\\\\\n",
    "p_1(x_2) = 1, & p_2(x_2) = (x_2 - x_1), & p_3(x_2) = 0, & \\ldots, & p_n(x_2) = 0\\\\\n",
    "p_1(x_3) = 1, & p_2(x_3) = (x_3 - x_1), & p_3(x_3) = (x_3 - x_1)(x_3 - x_2), & \\ldots, & p_n(x_3) = 0\\\\\n",
    "\\vdots\\\\\n",
    "p_1(x_n) = 1, & p_2(x_n) = (x_n - x_1), & p_3(x_n) = (x_n - x_1)(x_n - x_2), & \\ldots, & p_n(x_3) = \\prod_{j=1}^{n-1} (x_n - x_j)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "L = \n",
    "\\begin{bmatrix}\n",
    "1 & & & & & \\\\\n",
    "1 & (x_2 - x_1) &  & & &\\\\\n",
    "1 & (x_3 - x_1) & (x_3 - x_1)(x_3 - x_2) & & &\\\\\n",
    "1 & (x_4 - x_1) & (x_4 - x_1)(x_4 - x_2) & (x_4 - x_1)(x_4 - x_2)(x_4 - x_3)& &\\\\\n",
    "\\vdots & \\vdots & \\vdots                 &  \\vdots                          & \\ddots & \\\\\n",
    "1 & (x_n - x_1) & (x_n - x_1)(x_n - x_2) & (x_n - x_1)(x_n - x_2)(x_n - x_3)& \\ldots & \\prod_{j=1}^{n-1} (x_n - x_j)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Hence, the coefficients in the equation $Lc = f$ can be computed by forward substitution. In the next section, we shall see how this basis leads to Newton's interpolation formula. This is one of the best interpolation formulas, with respect to flexibility, computational economy and numerical stability. \n",
    "\n",
    "If a polynomial $p(x)$ is given in the form above, then it can be evaluated as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(x) &= c_1p_1(x) + c_2p_2(x) + c_3p_3(x) + c_4p_4(x) + \\ldots + c_n p_n(x)\\\\\n",
    "&= c_1 + c_2(x - x_1) + c_3(x - x_1)(x - x_2) + c_4(x - x_1)(x - x_2)(x - x_3) + c_5(x - x_1)(x - x_2)(x - x_3)(x - x_4) + \\ldots + c_n \\prod_{j=1}^{n-1} (x - x_j)\\\\\n",
    "&= c_1 + (x - x_1)\\left[c_2 + c_3(x - x_2) + c_4(x - x_2)(x - x_3)+ c_5(x - x_2)(x - x_3)(x - x_4) + \\ldots + c_n\\prod_{j=2}^{n-1} (x - x_j)\\right]\\\\\n",
    "&= c_1 + (x - x_1)\\left[c_2 + (x - x_2)\\left\\{c_3+ c_4(x - x_3) + c_5 (x - x_3)(x - x_4)+\\ldots + c_n\\prod_{j=3}^{n-1} (x - x_j)\\right\\}\\right]\\\\\n",
    "&= c_1 + (x - x_1)\\left[c_2 + (x - x_2)\\left\\{c_3 + (x - x_3)\\left(c_4 + c_5 (x - x_4)+\\ldots + c_n\\prod_{j=4}^{n-1} (x - x_j)\\right)\\right\\}\\right]\\\\\n",
    "& \\vdots \\\\\n",
    "&= \\ldots + c_{n-3} + (x - x_{n-3})[c_{n-2}+(x - x_{n-2})\\{c_{n-1} + c_n(x - x_{n-1})\\}]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This can be evaluated by a recursion formula similar to Horner's rule.\n",
    "\n",
    "Other bases of $\\mathcal{P}_n$ are sometimes more advantageous. Let $x_i$, $i=1:n$ be distinct interpolation points. The Lagrange $\\mathcal{l}_j(x)$ used in are polynomials of degree $n-1$\n",
    "\n",
    "$\n",
    "\\begin{array}{cc}\n",
    "\\mathcal{l}_j(x)=\\prod_{i = 1\\\\ i \\ne j}^{n} \\frac{x - x_i}{x_j - x_i}, & j = 1:n\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "where $x_i, i = 1:n$, are $n$ distinct real numbers, which satisfy\n",
    "\n",
    "$$\n",
    "\\mathcal{l}_j(x_i) = \\delta_{ij} = \n",
    "\\begin{cases}\n",
    "1, & i \\ne j\\\\\n",
    "0, & i = j\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
